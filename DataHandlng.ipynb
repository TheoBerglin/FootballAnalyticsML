{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data handling for football analytics\n",
    "\n",
    "Goal of the notebook is to handle all necessery data for the project. Should download data, should sort data and create data sets for analytics.\n",
    "\n",
    "## Imports below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the imports needed\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = r'C:\\Users\\theo_\\Documents\\Fotboll\\FootballAnalyticsML\\GameData'\n",
    "countries = ['England', 'Spain', 'Italy', 'Germany', 'France', 'Turkey', 'Greece', 'Neterlands', 'Belgium']\n",
    "url_start = \"http://www.football-data.co.uk/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help methods data downloading and storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_url(country):\n",
    "    return 'http://www.football-data.co.uk/%sm.php' % country.lower()\n",
    "\n",
    "def get_country_path(country):\n",
    "    return os.path.join(save_directory, country)\n",
    "\n",
    "def check_create_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "def get_all_files(directory, file_ending):\n",
    "    return_files = list()\n",
    "    for path, subdirs, files in os.walk(directory):\n",
    "        for name in files:\n",
    "            if file_ending in name:\n",
    "                return_files.append(os.path.join(path, name))\n",
    "    return return_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data downloading\n",
    "Data downloading from www.football-data.uk for all leagues in countries. \n",
    "\n",
    "## Current countries \n",
    "\n",
    "* England\n",
    "* Spain\n",
    "* Italy\n",
    "* Germany\n",
    "* France\n",
    "* Turkey\n",
    "* Greece\n",
    "* Netherlands\n",
    "* Belgium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_game_data():\n",
    "    print('Begininning to download data for %d countries' % len(countries))\n",
    "    print('---------------------------------------------------')\n",
    "    for country in countries:\n",
    "        print('Currently downloading data for country: %s' % country)\n",
    "        download_country_data(country)\n",
    "    print('---------------------------------------------------')\n",
    "    print('Done with downloading data')\n",
    "\n",
    "def download_country_data(country):\n",
    "    rep = {\"mmz4281/\": \"\", \"/\": \"_\"}\n",
    "    rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    \n",
    "    country_path = get_country_path(country)\n",
    "    check_create_path(country_path)\n",
    "    country_url = get_country_url(country)\n",
    "    files_downloaded = 0\n",
    "    for a in scrape_links(country_url):\n",
    "        if \".csv\" in a['href']:\n",
    "            name_of_file = pattern.sub(lambda m: rep[re.escape(m.group(0))], a['href'])\n",
    "            league_path = os.path.join(country_path, a.string)\n",
    "            check_create_path(league_path)\n",
    "            urllib.request.urlretrieve(url_start + a['href'], os.path.join(league_path, name_of_file))\n",
    "            files_downloaded += 1\n",
    "    print('Done! Downloaded %d files' % files_downloaded)\n",
    "\n",
    "def scrape_links(url):\n",
    "    source_code = requests.get(url)\n",
    "    plain_text = source_code.content\n",
    "    soup = BeautifulSoup(plain_text, \"lxml\")\n",
    "    return soup.find_all('a', href=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begininning to download data for 9 countries\n",
      "---------------------------------------------------\n",
      "Currently downloading data for country: England\n",
      "Done! Downloaded 118 files\n",
      "Currently downloading data for country: Spain\n",
      "Done! Downloaded 49 files\n",
      "Currently downloading data for country: Italy\n",
      "Done! Downloaded 48 files\n",
      "Currently downloading data for country: Germany\n",
      "Done! Downloaded 52 files\n",
      "Currently downloading data for country: France\n",
      "Done! Downloaded 49 files\n",
      "Currently downloading data for country: Turkey\n",
      "Done! Downloaded 25 files\n",
      "Currently downloading data for country: Greece\n",
      "Done! Downloaded 25 files\n",
      "Currently downloading data for country: Neterlands\n",
      "Done! Downloaded 26 files\n",
      "Currently downloading data for country: Belgium\n",
      "Done! Downloaded 24 files\n",
      "---------------------------------------------------\n",
      "Done with downloading data\n"
     ]
    }
   ],
   "source": [
    "download_game_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data\n",
    "\n",
    "The data will contain some not so nice things. We need to clean the data by for example removing empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_empty_rows(data_frame):\n",
    "    data_frame = data_frame.dropna(how='all')\n",
    "    return data_frame\n",
    "def remove_empty_columns(data_frame):\n",
    "    data_frame = data_frame.loc[:, ~data_frame.columns.str.contains('Unnamed')]\n",
    "    return data_frame\n",
    "\n",
    "def clean_dataframe(data_frame):\n",
    "    data_frame = remove_empty_columns(data_frame)\n",
    "    data_frame = remove_empty_rows(data_frame)\n",
    "    return data_frame\n",
    " \n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\theo_\\Documents\\Fotboll\\FootballAnalyticsML\\GameData\\England\\Division 1\\0203_E1.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_all_files(save_directory, '.csv')\n",
    "\n",
    "\n",
    "class NullDevice():\n",
    "    def write(self, s):\n",
    "        pass\n",
    "\n",
    "original_stderr = sys.stderr  # keep a reference to STDOUT\n",
    "\n",
    "sys.stderr = NullDevice()  # redirect the real STDOUT\n",
    "for file in files:\n",
    "    try:\n",
    "        df = pd.read_csv(file,  error_bad_lines=False)\n",
    "        df = clean_dataframe(df)\n",
    "        df.to_csv(file, index=False)\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        print('Removing file: %s' % file)\n",
    "        os.remove(file)\n",
    "\n",
    "sys.stderr = original_stderr  # turn STDOUT back on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add important columns to each data set\n",
    "\n",
    "We want to add some information to the data set. For example table location. We might also want to add ELO-ranking, goal difference etc. All methods for doing this should be coded below\n",
    "\n",
    "## Help methods data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teams_in_df(df):\n",
    "    return pd.unique(df[['HomeTeam', 'AwayTeam']].values.ravel('K'))\n",
    "def add_new_column(df, column_name, value=0):\n",
    "    df[column_name] = value\n",
    "    return df\n",
    "\n",
    "def add_new_columns(df, columns, value=0):\n",
    "    for column_name in columns:\n",
    "        df = add_new_column(df, column_name, value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data sets should have the same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = get_all_files(save_directory, '.csv')\n",
    "headers = list()\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    a = df.columns\n",
    "    headers = np.concatenate((headers,a))\n",
    "    headers = np.unique(headers)\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    current_head = df.columns\n",
    "    for head in headers:\n",
    "        if head not in current_head:\n",
    "            df = add_new_column(df, head, np.nan)\n",
    "    df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data in to year, month, day\n",
    "As an initial important task we have to split the date so that we write dates in one way. We need to split the date to year, month and day as to simplify the creation of one data set with all leagues where the data is ordered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding separate date columns for 409 files\n",
      "------------------Done!-------------------\n"
     ]
    }
   ],
   "source": [
    "# Day, month, year\n",
    "def get_date_type(date):\n",
    "    date_split = split_date(date)\n",
    "    if len(date_split[-1]) == 4:\n",
    "        return 1\n",
    "    elif len(date_split[-1]) == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def split_date(date):\n",
    "    return date.split('/')\n",
    "\n",
    "def add_date(df,index, year, month, day):\n",
    "    df.at[index, 'Year'] = year\n",
    "    df.at[index, 'Month'] = month\n",
    "    df.at[index, 'Day'] = day\n",
    "    return df\n",
    "\n",
    "def get_full_year(year):\n",
    "    if int(year) > 70:\n",
    "        return '19%s' % year\n",
    "    else:\n",
    "        return '20%s' % year\n",
    "\n",
    "print('Adding separate date columns for %d files' %len(files))\n",
    "for file in files:\n",
    "    df = pd.read_csv(file,  error_bad_lines=False) \n",
    "    date_type = get_date_type(df.Date[0])\n",
    "    \n",
    "    if date_type == 0:\n",
    "        print(first_date, file)\n",
    "    else:\n",
    "        df = add_new_columns(df, ['Year', 'Month', 'Day'])\n",
    "        df = add_new_column(df, 'LastGame')\n",
    "        for index, row in df.iterrows():\n",
    "            if df.Date[index] == 'nan' or isinstance(df.Date[index],str)==False:\n",
    "                df = add_date(df, index, df.Year[index-1],df.Month[index-1],df.Day[index-1])\n",
    "                continue\n",
    "            date_split = split_date(df.Date[index])\n",
    "            if date_type == 2:\n",
    "                date_split[2] = get_full_year(date_split[2])\n",
    "            df = add_date(df, index, year=date_split[2], month=date_split[1], day=date_split[0])\n",
    "        df.at[index, 'LastGame'] = 1\n",
    "        df.to_csv(file, index=False)\n",
    "\n",
    "print('------------------Done!-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table location+Goal difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, teams):\n",
    "        # self.radius is an instance variable\n",
    "        self.teams = teams\n",
    "\n",
    "    def area(self):\n",
    "        return self.pi * (self.radius ** 2)\n",
    "\n",
    "\n",
    "\n",
    "def add_game_number(df):\n",
    "    teams = get_teams_in_df(df)\n",
    "    games_played = dict()\n",
    "\n",
    "    for team in teams:\n",
    "        games_played[team]=1\n",
    "        \n",
    "    df = add_new_column(df, 'HomeTeamGames')\n",
    "    df = add_new_column(df, 'AwayTeamGames')\n",
    "    for index, row in df.iterrows():\n",
    "        HT = row['HomeTeam']\n",
    "        AT = row['AwayTeam']\n",
    "        df.at[index, 'HomeTeamGames'] = games_played[HT]\n",
    "        df.at[index, 'AwayTeamGames'] = games_played[AT]\n",
    "        games_played[HT] += 1\n",
    "        games_played[AT] += 1\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_table_position(df):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = get_all_files(save_directory, '.csv')\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
